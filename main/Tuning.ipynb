{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ebaa23-5b2b-40a9-aea2-115b1167cee4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ed07e8-885c-4906-853a-2bed788f5222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.preprocessing_util import *\n",
    "from utils.encoder_lib import *\n",
    "from pandas import DataFrame\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b18d6db8-d0e8-4eb6-8502-85d4a2f1dd91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc83d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23fbb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_location_property_attributes(df:DataFrame, target_encoder_wrapper:TargetEncoderWrapper, is_training:bool) -> DataFrame :\n",
    "    _df = df.copy()\n",
    "    # Drop columns with no significance\n",
    "    _df = _df.drop('furnished', axis=1)\n",
    "    _df = _df.drop('elevation', axis=1)\n",
    "\n",
    "    # Numeric encoding\n",
    "    _df['flat_type'] = search_and_replace(_df, 'flat_type', '2', 2)\n",
    "    _df['flat_type'] = search_and_replace(_df, 'flat_type', '3', 3)\n",
    "    _df['flat_type'] = search_and_replace(_df, 'flat_type', '4', 4)\n",
    "    _df['flat_type'] = search_and_replace(_df, 'flat_type', '5', 5)\n",
    "    _df['flat_type'] = search_and_replace(_df, 'flat_type', 'executive', 6)\n",
    "\n",
    "    # Target encoding\n",
    "    if is_training:\n",
    "        _df = target_encoder_wrapper.fit_transform(_df) \n",
    "    else:    \n",
    "        _df = target_encoder_wrapper.transform(_df) \n",
    "    \n",
    "    # OnehotEnoding\n",
    "    _df = pd.concat([generate_dummies(_df, 'town'),\n",
    "               _df,\n",
    "          ], axis=1)\n",
    "\n",
    "    return _df\n",
    "\n",
    "def preprocess_rent_date(df:DataFrame) -> DataFrame :\n",
    "    _df =df.copy()\n",
    "\n",
    "    # rent year and month\n",
    "    _df['rent_approval_year'] = pd.to_datetime(_df['rent_approval_date']).dt.year\n",
    "    _df['rent_approval_month'] = pd.to_datetime(_df['rent_approval_date']).dt.month\n",
    "\n",
    "    # age of house when rental begin\n",
    "    _df['age_at_rental_start'] = _df['rent_approval_year'] - _df['lease_commence_date']\n",
    "    \n",
    "    _df = _df.drop(columns=['rent_approval_date','lease_commence_date'])\n",
    "    return _df\n",
    "\n",
    "def preprocess_geographic_location(df:DataFrame) -> DataFrame :\n",
    "    _df =df.copy()\n",
    "    mrt_exist_df = pd.read_csv('../auxiliary-data/sg-mrt-existing-stations.csv')\n",
    "    mrt_planned_df = pd.read_csv('../auxiliary-data/sg-mrt-planned-stations.csv')\n",
    "    primary_school_df = pd.read_csv('../auxiliary-data/sg-primary-schools.csv')\n",
    "    # Calculate distances for each row in df\n",
    "    _df['dist_mrt_exist'] = _df.apply(lambda row: calculate_distance(row['latitude'], row['longitude'], mrt_exist_df), axis=1)\n",
    "    _df['dist_mrt_planned'] = _df.apply(lambda row: calculate_distance(row['latitude'], row['longitude'], mrt_planned_df), axis=1)\n",
    "    _df['dist_primary_school'] = _df.apply(lambda row: calculate_distance(row['latitude'], row['longitude'], primary_school_df), axis=1)\n",
    "    return _df\n",
    "\n",
    "def preprocess_subzone_planning_area_region(df:DataFrame) -> DataFrame :\n",
    "    _df =df.copy()\n",
    "    return _df\n",
    "\n",
    "def preprocess_others1(df:DataFrame) -> DataFrame :\n",
    "    _df =df.copy()\n",
    "    return _df\n",
    "\n",
    "def remove_columns(df:DataFrame) -> DataFrame :\n",
    "    _df =df.copy()\n",
    "    return _df\n",
    "\n",
    "def preprocess(df:DataFrame, target_encoder_wrapper:TargetEncoderWrapper, is_training:bool) -> DataFrame:\n",
    "    _df = df.copy()\n",
    "\n",
    "    # Proprocess property location attributes\n",
    "    _df = preprocess_location_property_attributes(_df, target_encoder_wrapper, is_training)\n",
    "\n",
    "    # Process rent approval date data\n",
    "    _df = preprocess_rent_date(_df)\n",
    "\n",
    "    _df=preprocess_geographic_location(_df)\n",
    "\n",
    "    _df=preprocess_subzone_planning_area_region(_df)\n",
    "\n",
    "    _df=preprocess_others1(_df)\n",
    "\n",
    "    _df=remove_columns(_df)\n",
    "\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d2aac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geographic calc take 1min10s+\n",
    "target_encoder_wrapper = TargetEncoderWrapper(feature_col='flat_model', target_col='monthly_rent', smoothing=10)\n",
    "df = preprocess(train, target_encoder_wrapper, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "313c0b71-1497-45ca-aa5f-1bb808b0c558",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>town_bedok</th>\n",
       "      <th>town_bishan</th>\n",
       "      <th>town_bukit batok</th>\n",
       "      <th>town_bukit merah</th>\n",
       "      <th>town_bukit panjang</th>\n",
       "      <th>town_bukit timah</th>\n",
       "      <th>town_central</th>\n",
       "      <th>town_choa chu kang</th>\n",
       "      <th>town_clementi</th>\n",
       "      <th>town_geylang</th>\n",
       "      <th>...</th>\n",
       "      <th>town_yishun</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>rent_approval_year</th>\n",
       "      <th>rent_approval_month</th>\n",
       "      <th>age_at_rental_start</th>\n",
       "      <th>dist_mrt_exist</th>\n",
       "      <th>dist_mrt_planned</th>\n",
       "      <th>dist_primary_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2370</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2370</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.005466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2636</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>2879</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.005081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2636</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.025345</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2370</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.061375</td>\n",
       "      <td>0.003058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2439</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>2636</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.051130</td>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>2612</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.004416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>2370</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    town_bedok  town_bishan  town_bukit batok  town_bukit merah  \\\n",
       "0        False        False             False             False   \n",
       "1         True        False             False             False   \n",
       "2        False        False             False             False   \n",
       "3        False        False             False             False   \n",
       "4        False        False             False             False   \n",
       "..         ...          ...               ...               ...   \n",
       "95       False        False             False             False   \n",
       "96       False        False             False             False   \n",
       "97       False        False             False             False   \n",
       "98        True        False             False             False   \n",
       "99       False        False             False             False   \n",
       "\n",
       "    town_bukit panjang  town_bukit timah  town_central  town_choa chu kang  \\\n",
       "0                False             False         False               False   \n",
       "1                False             False         False               False   \n",
       "2                False             False         False               False   \n",
       "3                False             False         False               False   \n",
       "4                False             False         False               False   \n",
       "..                 ...               ...           ...                 ...   \n",
       "95               False             False         False               False   \n",
       "96               False             False         False               False   \n",
       "97               False             False         False               False   \n",
       "98               False             False         False               False   \n",
       "99               False             False         False               False   \n",
       "\n",
       "    town_clementi  town_geylang  ...  town_yishun  flat_type  flat_model  \\\n",
       "0           False         False  ...        False          3        2370   \n",
       "1           False         False  ...        False          4        2370   \n",
       "2           False         False  ...        False          3        2636   \n",
       "3           False         False  ...        False          6        2879   \n",
       "4           False         False  ...        False          3        2636   \n",
       "..            ...           ...  ...          ...        ...         ...   \n",
       "95          False         False  ...         True          4        2370   \n",
       "96          False         False  ...        False          4        2439   \n",
       "97          False         False  ...        False          5        2636   \n",
       "98          False         False  ...        False          3        2612   \n",
       "99          False         False  ...         True          4        2370   \n",
       "\n",
       "    floor_area_sqm  rent_approval_year  rent_approval_month  \\\n",
       "0             67.0                2021                    9   \n",
       "1             92.0                2022                    5   \n",
       "2             67.0                2022                   10   \n",
       "3            149.0                2021                    8   \n",
       "4             68.0                2022                   11   \n",
       "..             ...                 ...                  ...   \n",
       "95            93.0                2023                    4   \n",
       "96            90.0                2021                    3   \n",
       "97           120.0                2021                    6   \n",
       "98            76.0                2021                    6   \n",
       "99            93.0                2022                   12   \n",
       "\n",
       "    age_at_rental_start  dist_mrt_exist  dist_mrt_planned  dist_primary_school  \n",
       "0                    38        0.006289          0.006071             0.003012  \n",
       "1                    44        0.008087          0.008135             0.005466  \n",
       "2                    51        0.001966          0.010649             0.003830  \n",
       "3                    28        0.013908          0.004643             0.005081  \n",
       "4                    50        0.001690          0.025345             0.002444  \n",
       "..                  ...             ...               ...                  ...  \n",
       "95                   38        0.001999          0.061375             0.003058  \n",
       "96                   22        0.007945          0.014608             0.002286  \n",
       "97                   22        0.006177          0.051130             0.002475  \n",
       "98                   37        0.008268          0.009826             0.004416  \n",
       "99                   37        0.003288          0.063301             0.001669  \n",
       "\n",
       "[100 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df.drop(columns=['street_name','block','town','region','planning_area','subzone','latitude','longitude','monthly_rent'])\n",
    "y_train = df['monthly_rent']\n",
    "X_train.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99474ea4-f821-4fc4-935f-d2df538d0813",
   "metadata": {},
   "source": [
    "### Use X and y to train a model based on 5-fold cross validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae5a1900-fa8e-4e27-855e-29567ba80157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b747a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf =KFold(n_splits=5)\n",
    "\n",
    "# Define a custom scoring function for RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def get_RMSE(clf, x, y):\n",
    "    \n",
    "    avg_RMSE = cross_val_score(clf, x, y, scoring=scorer, cv=kf, n_jobs=-1).mean()*-1\n",
    "    return (avg_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0317063",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_preprocess = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbe6ab50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;, LinearRegression())]),\n",
       "             param_grid={&#x27;classifier__fit_intercept&#x27;: [True, False]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;, LinearRegression())]),\n",
       "             param_grid={&#x27;classifier__fit_intercept&#x27;: [True, False]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        Pipeline(steps=[('imputer',\n",
       "                                                         SimpleImputer(strategy='most_frequent')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler())])),\n",
       "                                       ('classifier', LinearRegression())]),\n",
       "             param_grid={'classifier__fit_intercept': [True, False]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_LR = Pipeline([\n",
    "    ('preprocess',pipe_preprocess),\n",
    "    ('classifier', LinearRegression())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__fit_intercept':[True,False]\n",
    "}\n",
    "\n",
    "grid_LR = GridSearchCV(pipe_LR,param_grid,cv=kf,scoring=scorer)\n",
    "\n",
    "grid_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ffedad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__fit_intercept': True}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0acce8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 Pipeline(steps=[('imputer',\n",
       "                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                 ('scaler', StandardScaler())])),\n",
       "                ('classifier', LinearRegression())])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f7f5195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_training for LR: 509.29477097399723\n"
     ]
    }
   ],
   "source": [
    "RMSE_LR = get_RMSE(grid_LR.best_estimator_,X_train,y_train)\n",
    "print('RMSE_training for LR:', RMSE_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3fe5f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        DecisionTreeRegressor())]),\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [1, 5, 10, 15]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        DecisionTreeRegressor())]),\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [1, 5, 10, 15]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        Pipeline(steps=[('imputer',\n",
       "                                                         SimpleImputer(strategy='most_frequent')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler())])),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeRegressor())]),\n",
       "             param_grid={'classifier__max_depth': [1, 5, 10, 15]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_DTR = Pipeline([\n",
    "    ('preprocess',pipe_preprocess),\n",
    "    ('classifier', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__max_depth':[1,5,10,15],\n",
    "}\n",
    "\n",
    "'''\n",
    "Best Param\n",
    "{'classifier__max_depth': 10}\n",
    "'''\n",
    "\n",
    "grid_DTR = GridSearchCV(pipe_DTR,param_grid,cv=kf,scoring=scorer)\n",
    "\n",
    "grid_DTR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c91caed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 10}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_DTR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d2c74e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeRegressor(max_depth=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeRegressor(max_depth=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 Pipeline(steps=[('imputer',\n",
       "                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                 ('scaler', StandardScaler())])),\n",
       "                ('classifier', DecisionTreeRegressor(max_depth=10))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_DTR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b84c1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_training for DTR: 519.6733977138528\n"
     ]
    }
   ],
   "source": [
    "RMSE_DTR=get_RMSE(grid_DTR.best_estimator_,X_train,y_train)\n",
    "print('RMSE_training for DTR:', RMSE_DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9237a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestRegressor())]),\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [2, 5, 10],\n",
       "                         &#x27;classifier__max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 0.3, 0.5,\n",
       "                                                      1],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [10, 100, 1000]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        RandomForestRegressor())]),\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [2, 5, 10],\n",
       "                         &#x27;classifier__max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, 0.3, 0.5,\n",
       "                                                      1],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [10, 100, 1000]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, RandomForestRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        Pipeline(steps=[('imputer',\n",
       "                                                         SimpleImputer(strategy='most_frequent')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler())])),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestRegressor())]),\n",
       "             param_grid={'classifier__max_depth': [2, 5, 10],\n",
       "                         'classifier__max_features': ['sqrt', 'log2', 0.3, 0.5,\n",
       "                                                      1],\n",
       "                         'classifier__n_estimators': [10, 100, 1000]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_RFR = Pipeline([\n",
    "    ('preprocess',pipe_preprocess),\n",
    "    ('classifier', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators':[10, 100, 1000],\n",
    "    'classifier__max_depth':[2,5,10],\n",
    "    'classifier__max_features':['sqrt','log2',0.3,0.5,1]\n",
    "}\n",
    "\n",
    "'''\n",
    "Best Param\n",
    "{'classifier__max_depth': 10,\n",
    " 'classifier__max_features': 0.5,\n",
    " 'classifier__n_estimators': 1000}\n",
    "'''\n",
    "\n",
    "grid_RFR = GridSearchCV(pipe_RFR,param_grid,cv=kf,scoring=scorer)\n",
    "\n",
    "grid_RFR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d380f974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 10,\n",
       " 'classifier__max_features': 0.5,\n",
       " 'classifier__n_estimators': 1000}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_RFR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16627e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_training for RFR: 498.20184657884874\n"
     ]
    }
   ],
   "source": [
    "RMSE_RFR=get_RMSE(grid_RFR.best_estimator_,X_train,y_train)\n",
    "print('RMSE_training for RFR:', RMSE_RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d439a98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        GradientBoostingRegressor())]),\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
       "                         &#x27;classifier__max_depth&#x27;: [3, 6, 9],\n",
       "                         &#x27;classifier__min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [10, 100, 300]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        GradientBoostingRegressor())]),\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
       "                         &#x27;classifier__max_depth&#x27;: [3, 6, 9],\n",
       "                         &#x27;classifier__min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [10, 100, 300]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;, GradientBoostingRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        Pipeline(steps=[('imputer',\n",
       "                                                         SimpleImputer(strategy='most_frequent')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler())])),\n",
       "                                       ('classifier',\n",
       "                                        GradientBoostingRegressor())]),\n",
       "             param_grid={'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
       "                         'classifier__max_depth': [3, 6, 9],\n",
       "                         'classifier__min_samples_leaf': [1, 2, 3],\n",
       "                         'classifier__n_estimators': [10, 100, 300]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_GBR = Pipeline([\n",
    "    ('preprocess',pipe_preprocess),\n",
    "    ('classifier', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_estimators':[10, 100, 300],\n",
    "    'classifier__learning_rate':[0.05,0.1,0.2],\n",
    "    'classifier__min_samples_leaf':[1,2,3],\n",
    "    'classifier__max_depth':[3,6,9],\n",
    "}\n",
    "\n",
    "'''\n",
    "Best Param\n",
    "{'classifier__learning_rate': 0.05,\n",
    " 'classifier__max_depth': 6,\n",
    " 'classifier__min_samples_leaf': 3,\n",
    " 'classifier__n_estimators': 300}\n",
    "'''\n",
    "\n",
    "grid_GBR = GridSearchCV(pipe_GBR,param_grid,cv=kf,scoring=scorer)\n",
    "\n",
    "grid_GBR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "640887a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.05,\n",
       " 'classifier__max_depth': 6,\n",
       " 'classifier__min_samples_leaf': 3,\n",
       " 'classifier__n_estimators': 300}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "394edba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_training for GBR: 485.8548281442342\n"
     ]
    }
   ],
   "source": [
    "RMSE_GBR=get_RMSE(grid_GBR.best_estimator_,X_train,y_train)\n",
    "print('RMSE_training for GBR:', RMSE_GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ebff37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2588.793750\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1058\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2591.033333\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.762500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1059\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2592.812500\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1057\n",
      "[LightGBM] [Info] Number of data points in the train set: 48000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2589.239583\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1060\n",
      "[LightGBM] [Info] Number of data points in the train set: 60000, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 2590.328333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                      objective=&#x27;regression&#x27;,\n",
       "                                                      random_state=0))]),\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: [0.01, 0.05],\n",
       "                         &#x27;classifier__max_depth&#x27;: [3, 6, 9],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                         SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                        (&#x27;scaler&#x27;,\n",
       "                                                         StandardScaler())])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                      objective=&#x27;regression&#x27;,\n",
       "                                                      random_state=0))]),\n",
       "             param_grid={&#x27;classifier__learning_rate&#x27;: [0.01, 0.05],\n",
       "                         &#x27;classifier__max_depth&#x27;: [3, 6, 9],\n",
       "                         &#x27;classifier__n_estimators&#x27;: [100, 150]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                 (&#x27;scaler&#x27;, StandardScaler())])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;,\n",
       "                               random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        Pipeline(steps=[('imputer',\n",
       "                                                         SimpleImputer(strategy='most_frequent')),\n",
       "                                                        ('scaler',\n",
       "                                                         StandardScaler())])),\n",
       "                                       ('classifier',\n",
       "                                        LGBMRegressor(metric='rmse',\n",
       "                                                      objective='regression',\n",
       "                                                      random_state=0))]),\n",
       "             param_grid={'classifier__learning_rate': [0.01, 0.05],\n",
       "                         'classifier__max_depth': [3, 6, 9],\n",
       "                         'classifier__n_estimators': [100, 150]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_LGB = Pipeline([('preprocessor', pipe_preprocess),\n",
    "                     ('classifier', lgb.LGBMRegressor(objective='regression',\n",
    "                                                       metric='rmse',\n",
    "                                                       random_state=0))])\n",
    "\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [100,150],\n",
    "    'classifier__learning_rate': [0.01,0.05],\n",
    "    'classifier__max_depth': [3,6,9]\n",
    "    }\n",
    "\n",
    "'''\n",
    "Best Param\n",
    "{'classifier__learning_rate': 0.05,\n",
    " 'classifier__max_depth': 9,\n",
    " 'classifier__n_estimators': 150}\n",
    "'''\n",
    "\n",
    "grid_LGB = GridSearchCV(pipe_LGB, param_grid,cv=kf,scoring=scorer)\n",
    "\n",
    "grid_LGB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d631d489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.05,\n",
       " 'classifier__max_depth': 9,\n",
       " 'classifier__n_estimators': 150}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_LGB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8eba982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_training for LGB: 486.23125098702275\n"
     ]
    }
   ],
   "source": [
    "RMSE_LGB=get_RMSE(grid_LGB.best_estimator_,X_train,y_train)\n",
    "print('RMSE_training for LGB:', RMSE_LGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d378ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTree': 519.6733977138528,\n",
      " 'GradientBoosting': 485.8548281442342,\n",
      " 'LightGBM': 486.23125098702275,\n",
      " 'LinearRegression': 509.29477097399723,\n",
      " 'RandomForst': 498.20184657884874}\n"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"LinearRegression\":RMSE_LR,\n",
    "    \"DecisionTree\":RMSE_DTR,\n",
    "    \"RandomForst\":RMSE_RFR,\n",
    "    \"GradientBoosting\":RMSE_GBR,\n",
    "    \"LightGBM\":RMSE_LGB\n",
    "}\n",
    "pprint(result)\n",
    "\n",
    "'''\n",
    "{'DecisionTree': 519.6733977138528,\n",
    " 'GradientBoosting': 485.8548281442342,\n",
    " 'LightGBM': 486.23125098702275,\n",
    " 'LinearRegression': 509.29477097399723,\n",
    " 'RandomForst': 498.20184657884874}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7ca7f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 60000, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2590.328333\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;GB&#x27;,\n",
       "                                                      Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                                       Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                        SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                       (&#x27;scaler&#x27;,\n",
       "                                                                                        StandardScaler())])),\n",
       "                                                                      (&#x27;classifier&#x27;,\n",
       "                                                                       GradientBoostingRegressor())])),\n",
       "                                                     (&#x27;RF&#x27;,\n",
       "                                                      Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                                       Pipeline(steps=[(&#x27;imputer&#x27;,...\n",
       "                                                                       LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                                                     objective=&#x27;regression&#x27;,\n",
       "                                                                                     random_state=0))]))],\n",
       "                                         final_estimator=LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                                       objective=&#x27;regression&#x27;,\n",
       "                                                                       random_state=0),\n",
       "                                         n_jobs=-1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;final_estimator__learning_rate&#x27;: [0.05, 0.1],\n",
       "                         &#x27;final_estimator__max_depth&#x27;: [3, 6, 9],\n",
       "                         &#x27;final_estimator__n_estimators&#x27;: [50, 100, 150]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False), verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=StackingRegressor(estimators=[(&#x27;GB&#x27;,\n",
       "                                                      Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                                       Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                        SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                       (&#x27;scaler&#x27;,\n",
       "                                                                                        StandardScaler())])),\n",
       "                                                                      (&#x27;classifier&#x27;,\n",
       "                                                                       GradientBoostingRegressor())])),\n",
       "                                                     (&#x27;RF&#x27;,\n",
       "                                                      Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                                       Pipeline(steps=[(&#x27;imputer&#x27;,...\n",
       "                                                                       LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                                                     objective=&#x27;regression&#x27;,\n",
       "                                                                                     random_state=0))]))],\n",
       "                                         final_estimator=LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                                       objective=&#x27;regression&#x27;,\n",
       "                                                                       random_state=0),\n",
       "                                         n_jobs=-1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;final_estimator__learning_rate&#x27;: [0.05, 0.1],\n",
       "                         &#x27;final_estimator__max_depth&#x27;: [3, 6, 9],\n",
       "                         &#x27;final_estimator__n_estimators&#x27;: [50, 100, 150]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False), verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;GB&#x27;,\n",
       "                               Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                 SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                (&#x27;scaler&#x27;,\n",
       "                                                                 StandardScaler())])),\n",
       "                                               (&#x27;classifier&#x27;,\n",
       "                                                GradientBoostingRegressor())])),\n",
       "                              (&#x27;RF&#x27;,\n",
       "                               Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                 SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                (&#x27;scaler&#x27;,\n",
       "                                                                 StandardScaler())])),\n",
       "                                               (&#x27;cl...ier&#x27;,\n",
       "                                                RandomForestRegressor())])),\n",
       "                              (&#x27;LGB&#x27;,\n",
       "                               Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                                Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                 SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                (&#x27;scaler&#x27;,\n",
       "                                                                 StandardScaler())])),\n",
       "                                               (&#x27;classifier&#x27;,\n",
       "                                                LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                              objective=&#x27;regression&#x27;,\n",
       "                                                              random_state=0))]))],\n",
       "                  final_estimator=LGBMRegressor(metric=&#x27;rmse&#x27;,\n",
       "                                                objective=&#x27;regression&#x27;,\n",
       "                                                random_state=0),\n",
       "                  n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RF</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(metric=&#x27;rmse&#x27;, objective=&#x27;regression&#x27;, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=StackingRegressor(estimators=[('GB',\n",
       "                                                      Pipeline(steps=[('preprocess',\n",
       "                                                                       Pipeline(steps=[('imputer',\n",
       "                                                                                        SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                       ('scaler',\n",
       "                                                                                        StandardScaler())])),\n",
       "                                                                      ('classifier',\n",
       "                                                                       GradientBoostingRegressor())])),\n",
       "                                                     ('RF',\n",
       "                                                      Pipeline(steps=[('preprocess',\n",
       "                                                                       Pipeline(steps=[('imputer',...\n",
       "                                                                       LGBMRegressor(metric='rmse',\n",
       "                                                                                     objective='regression',\n",
       "                                                                                     random_state=0))]))],\n",
       "                                         final_estimator=LGBMRegressor(metric='rmse',\n",
       "                                                                       objective='regression',\n",
       "                                                                       random_state=0),\n",
       "                                         n_jobs=-1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'final_estimator__learning_rate': [0.05, 0.1],\n",
       "                         'final_estimator__max_depth': [3, 6, 9],\n",
       "                         'final_estimator__n_estimators': [50, 100, 150]},\n",
       "             scoring=make_scorer(rmse, greater_is_better=False), verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking with top 3 Model\n",
    "\n",
    "GB = pipe_GBR\n",
    "RF = pipe_RFR\n",
    "LGB = pipe_LGB\n",
    "\n",
    "estimators = [\n",
    "    ('GB',GB),\n",
    "    ('RF',RF),\n",
    "    ('LGB',LGB),\n",
    "]\n",
    "\n",
    "final_estimator = lgb.LGBMRegressor(objective='regression',\n",
    "                                                       metric='rmse',\n",
    "                                                       random_state=0)\n",
    "\n",
    "stacking_classifier = StackingRegressor(estimators=estimators,\n",
    "                                         final_estimator=final_estimator, n_jobs=-1)\n",
    "\n",
    "param_grid = {'final_estimator__n_estimators': [50, 100, 150],\n",
    "              'final_estimator__learning_rate': [0.05,0.1],\n",
    "              'final_estimator__max_depth': [3, 6, 9]}\n",
    "\n",
    "'''\n",
    "{'final_estimator__learning_rate': 0.05,\n",
    " 'final_estimator__max_depth': 3,\n",
    " 'final_estimator__n_estimators': 100}\n",
    "'''\n",
    "\n",
    "grid_stacking = GridSearchCV(stacking_classifier, param_grid,\n",
    "                             cv=kf, scoring=scorer, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid_stacking.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18fc83c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_estimator__learning_rate': 0.05,\n",
       " 'final_estimator__max_depth': 3,\n",
       " 'final_estimator__n_estimators': 100}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_stacking.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b0d3a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_training for STACK: 486.371534879068\n"
     ]
    }
   ],
   "source": [
    "RMSE_STACK=get_RMSE(grid_stacking.best_estimator_,X_train,y_train)\n",
    "print('RMSE_training for STACK:', RMSE_STACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "460bad39",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'monthly_rent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bader\\.conda\\envs\\school\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'monthly_rent'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bader\\OneDrive - National University of Singapore\\Modules\\CS5228\\CS5228-ML-Project\\main\\Preprocessing.ipynb Cell 33\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Test\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test \u001b[39m=\u001b[39m preprocess(test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_test \u001b[39m=\u001b[39m X_test\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mflat_model\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mstreet_name\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtown\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mregion\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mplanning_area\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msubzone\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlongitude\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\bader\\OneDrive - National University of Singapore\\Modules\\CS5228\\CS5228-ML-Project\\main\\Preprocessing.ipynb Cell 33\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m _df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Proprocess property location attributes\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m _df \u001b[39m=\u001b[39m preprocess_location_property_attributes(_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Process rent approval date data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m _df \u001b[39m=\u001b[39m preprocess_rent_date(_df)\n",
      "\u001b[1;32mc:\\Users\\bader\\OneDrive - National University of Singapore\\Modules\\CS5228\\CS5228-ML-Project\\main\\Preprocessing.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m clean_replace_numeric(_df, \u001b[39m'\u001b[39m\u001b[39mflat_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexecutive\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m6\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Target encoding\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m target_encode(_df, \u001b[39m'\u001b[39;49m\u001b[39mflat_model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m format_integer(_df, \u001b[39m'\u001b[39m\u001b[39mflat_model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bader/OneDrive%20-%20National%20University%20of%20Singapore/Modules/CS5228/CS5228-ML-Project/main/Preprocessing.ipynb#X53sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# OnehotEnoding\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bader\\OneDrive - National University of Singapore\\Modules\\CS5228\\CS5228-ML-Project\\main\\utils\\preprocessing_util.py:69\u001b[0m, in \u001b[0;36mtarget_encode\u001b[1;34m(df, feature)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtarget_encode\u001b[39m(df, feature):\n\u001b[0;32m     68\u001b[0m     target_encoder_smooth \u001b[39m=\u001b[39m ce\u001b[39m.\u001b[39mTargetEncoder(cols\u001b[39m=\u001b[39m[feature], smoothing\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m     target_encoder_smooth\u001b[39m.\u001b[39mfit(df[feature], df[\u001b[39m\"\u001b[39;49m\u001b[39mmonthly_rent\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     70\u001b[0m     df[feature] \u001b[39m=\u001b[39m target_encoder_smooth\u001b[39m.\u001b[39mtransform(df[feature])\n\u001b[0;32m     71\u001b[0m     df[feature] \u001b[39m=\u001b[39m df[feature]\u001b[39m.\u001b[39mround()\n",
      "File \u001b[1;32mc:\\Users\\bader\\.conda\\envs\\school\\lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\bader\\.conda\\envs\\school\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'monthly_rent'"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "X_test = preprocess(test)\n",
    "X_test = X_test.drop(columns=['flat_model','street_name','block','town','region','planning_area','subzone','latitude','longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e0b7a-257d-4baa-a277-e8cff330a0aa",
   "metadata": {},
   "source": [
    "### EDA only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07896aeb-e199-4094-a373-6a9080003349",
   "metadata": {},
   "source": [
    "### Monthly rent distribution for kfold=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7892a3f-7683-4e34-b0ce-cce88610a76b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.subplot(3,3,1)\n",
    "df['monthly_rent'].hist()\n",
    "plt.title('Full monthly_rent distribution')\n",
    "for i in range(5):    \n",
    "    plt.subplot(3,3,i+2)\n",
    "    df[df['kfold'] == i]['monthly_rent'].hist()\n",
    "    plt.title(f'kfold={i} monthly_rent distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecd0f2-65db-49f5-bf7d-812ea065ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
